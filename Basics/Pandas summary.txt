ðŸ§± Creating DataFrames
â€¢	pd.DataFrame(data) â€“ create a DataFrame
â€¢	pd.read_csv('file.csv') â€“ read CSV file
â€¢	df.to_csv('file.csv') â€“ save to CSV
â€¢	df.to_excel(file_nm, index=False)
type(var) -> type of the variable
________________________________________
ðŸ“„ Viewing & Exploring
â€¢	df.head() â€“ first 5 rows
â€¢	df.tail() â€“ last 5 rows
â€¢	df.info() â€“ column types, non-nulls
â€¢	df.describe() â€“ stats summary
â€¢	df.shape â€“ a tuple -> (rows, columns)
â€¢	df.columns â€“ column names -> returns a Pandas Index object, which behaves like a list but is not exactly one. You can convert it with list(df.columns)
________________________________________
ðŸ§¹ Cleaning Data
â€¢	new = df.drop(columns=['col']) â€“ drop column -- or df.drop(columns=['col'], inplace=True)
â€¢	new = df.rename(columns={'old': 'new'}) â€“ rename â€“ or df.rename(columns={'old': 'new'}, inplace=True)
â€¢	new = df.dropna() â€“ drop nulls
â€¢	new =df.fillna(value) â€“ fill nulls
â€¢	df.duplicated() â€“ find duplicates â€“ Returns a column with an index
â€¢	 duplicates_list = df.duplicated().tolist() convertes Booleans seris to list
â€¢	new =df.drop_duplicates() â€“ remove duplicates
________________________________________
ðŸ” Filtering & Selecting
â€¢	df['col'] or df.col â€“ select column
â€¢	df[['col1', 'col2']] â€“ multiple columns

â€¢	df[df['col'] > 5] â€“ filter rows
â€¢	df.loc[0] â€“ row by label
â€¢	df.iloc[0] â€“ row by index
â€¢	
â€¢	df = df[df["dist_PL"] > 1]
â€¢	df = df.loc[df["dist_PL"] > 1]
â€¢	df = df.query("dist_PL > 1")
â€¢	df = df[df["dist_PL"].isin([2, 3, 4])]

# ADDS LIST COVERS AS A COL TO THE DF    
        df.loc[:, "Covers"] = Covers
# UPDATES VALUE OF COL Covers at index 100 to Hello 
df.loc[100, "Covers"] = "Hello"
________________________________________
ðŸ”„ Modifying
â€¢	df['new'] = df['a'] + df['b'] â€“ create new col
â€¢	df.apply(func) â€“ apply function
â€¢	df.map() â€“ element-wise mapping
â€¢	df.replace(old, new) â€“ replace values
â€¢	df.astype(type) â€“ convert type
________________________________________
ðŸ“Š Grouping & Aggregation
â€¢	df.groupby('col').sum() â€“ group & sum
â€¢	df.groupby('col').agg({'x': 'mean', 'y': 'max'}) â€“ multiple aggs
â€¢	df.pivot_table(values='x', index='y') â€“ pivot summary

â€¢	df["dist_Key"] = df.groupby("track_stdz")["Key"].transform("nunique")
________________________________________
ðŸ“ˆ Sorting
â€¢	df.sort_values('col') â€“ sort by column
â€¢	df.sort_values(['a', 'b'], ascending=[True, False]) â€“ multi-sort
________________________________________
ðŸ”— Merging & Joining
â€¢	pd.concat([df1, df2]) â€“ stack DataFrames
â€¢	df.merge(df2, on='col') â€“ SQL-style join
â€¢	df.join(df2) â€“ join on index (no used linking key)


# KEEP ONLY SELECTED COLS.
df = df.loc[:, col_names]

# BELOW TO FORCE GROUPS WHERE ONE AT LEAST ONE IS DEAD
# CREATE NEW COL CONVERTING
df["Key"] = df["not_miss"].astype(str)

df.shape returns a tuple (rows, columns)
df.shape[0] returns rows

my_list = [x for x in df['column_name']]
my_list = df['column_name'].tolist()
